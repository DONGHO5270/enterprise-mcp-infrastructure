version: '3.8'

# 온디맨드 MCP 서비스 Docker Compose 파일

# 전역 UTF-8 인코딩 설정
x-encoding-env: &encoding-env
  LANG: C.UTF-8
  LC_ALL: C.UTF-8
  PYTHONIOENCODING: utf-8
  TZ: Asia/Seoul

networks:
  mcp-network:
    external: true

volumes:
  hdap-logs:
  hdap-runtime:
  mcp-router-logs:
  playwright-browsers:
  taskmaster-data:
  mermaid-output:
  ollama-data:

services:
  # MCP Router - 중앙 라우터 (상시 실행)
  mcp-router:
    build:
      context: ../../services/mcp-router
      dockerfile: Dockerfile
    container_name: mcp-router
    restart: unless-stopped
    networks:
      - mcp-network
    ports:
      - "3100:3000"
    environment:
      <<: *encoding-env
      NODE_ENV: production
      LOG_LEVEL: info
      MAX_CONCURRENT_PROCESSES: 10
      REQUEST_TIMEOUT: 70000
      PROCESS_IDLE_TIMEOUT: 60000
      # Task 도구용 MCP 라우터 URL 설정
      MCP_ROUTER_URL: "http://localhost:3100"
      MCP_ROUTER_INTERNAL_URL: "http://mcp-router:3000"
    volumes:
      # MCP 서비스들 마운트 (상대 경로 사용)
      - ../../services/mcp:/app/services/mcp
      # 로그 볼륨
      - mcp-router-logs:/logs
      # Playwright 브라우저 캐시
      - playwright-browsers:/app/ms-playwright
      # 설정 파일 (상대 경로 사용)
      - ../../configs/api-keys.env:/app/configs/api-keys.env:ro
      - ../../configs/environment.env:/app/configs/environment.env:ro
      # Webapp 빌드 파일 (상대 경로 사용)
      - ../../webapp/build:/app/webapp/build:ro
      # WSL 파일시스템 접근
      - /mnt/c:/workspace
      # Docker 소켓 (프로세스 관리용)
      - /var/run/docker.sock:/var/run/docker.sock
    env_file:
      - ../../configs/api-keys.env
      - ../../configs/environment.env
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (res) => { process.exit(res.statusCode === 200 ? 0 : 1); }).on('error', () => { process.exit(1); })"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        # KST 시간대 정보 포함
        tag: "{{.ImageName}}/{{.Name}}/{{.ID}}"

  # Nginx API Gateway (기존과 동일)
  gateway:
    image: nginx:alpine
    container_name: mcp-gateway
    restart: unless-stopped
    networks:
      - mcp-network
    ports:
      - "${GATEWAY_PORT:-80}:80"
    volumes:
      - ../../configs/nginx-mcp.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - mcp-router
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Ollama Service for Local AI Models
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-service
    restart: unless-stopped
    networks:
      - mcp-network
    volumes:
      # Ollama 데이터 (로컬 빌드 버전으로 변경)
      - ollama-data:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
  # HDAP API Bridge - 23rd MCP Service
  hdap-api-bridge:
    image: hdap-api-bridge:mcp
    container_name: hdap-api-bridge-mcp
    restart: unless-stopped
    
    ports:
      - "23001:23001"
    
    environment:
      - NODE_ENV=production
      - PORT=23001
      - MCP_SERVICE_NAME=hdap-api-bridge
      - MCP_SERVICE_ID=23
      - MCP_ROUTER_URL=http://mcp-router:3100
      - LOG_LEVEL=info
      - HDAP_CONTINUOUS_MODE=true
      - HDAP_AUTO_START=true
      - MCP_MODE=http
      - DISABLE_STDIO=true
      
    volumes:
      - hdap-logs:/app/logs
      - hdap-runtime:/app/runtime
      
    networks:
      - mcp-network
      
    depends_on:
      - mcp-router
      
    healthcheck:
      test: ["CMD", "node", "-e", "console.log('healthy'); process.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
      
    labels:
      - "mcp.service.name=hdap-api-bridge"
      - "mcp.service.id=23"
      - "mcp.service.version=1.0.0"
      - "mcp.service.type=ai-api"
      - "mcp.service.cost-saving=100%"
      
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.2'

